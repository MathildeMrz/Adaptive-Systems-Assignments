{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import re\n","import datetime"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from gensim import corpora\n","from gensim import models\n","from gensim import similarities\n","from pprint import pprint  # pretty-printer"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from nltk import PorterStemmer\n","from nltk.corpus import stopwords"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["init_t: datetime = datetime.datetime.now()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["documents1 = [\n","    \"Human machine survey computer interface interface eps time for lab abc computer applications user\",\n","    \"A survey of user opinion of computer system user response time computer user interface interface\",\n","    \"The EPS user users interfaces interface human interface computer human management system user\",\n","    \"System and human interface interface engineering testing of EPS computer user\",\n","    \"Relation of users perceived response time to error measurement trees\",\n","    \"The generation of random binary unordered paths minors user user computer\",\n","    \"The intersection graph of paths in trees paths trees\",\n","    \"Graph minors IV Widths of trees and well quasi ordering graph paths\",\n","    \"Graph minors A tree paths binary trees graphs\",\n","]"]},{"cell_type":"markdown","metadata":{},"source":["another corpus (example in slide)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["documents = [\"eat turkey on turkey day holiday\",\n","              \"i like to eat cake on holiday\",\n","              \"turkey trot race on thanksgiving holiday\",\n","              \"snail race the turtle\",\n","              \"time travel space race\",\n","              \"movie on thanksgiving\",\n","              \"movie at air and space museum is cool movie\",\n","              \"aspiring movie star\"]"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["porter = PorterStemmer()"]},{"cell_type":"markdown","metadata":{},"source":["remove common words and tokenize"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["[['eat', 'turkey', 'turkey', 'day', 'holiday'],\n"," ['like', 'eat', 'cake', 'holiday'],\n"," ['turkey', 'trot', 'race', 'thanksgiv', 'holiday'],\n"," ['snail', 'race', 'turtl'],\n"," ['time', 'travel', 'space', 'race'],\n"," ['movi', 'thanksgiv'],\n"," ['movi', 'air', 'space', 'museum', 'cool', 'movi'],\n"," ['aspir', 'movi', 'star']]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["stoplist = stopwords.words('english')\n","texts = [\n","    [porter.stem(word) for word in document.lower().split() if word not in stoplist]\n","    for document in documents\n","]\n","texts"]},{"cell_type":"markdown","metadata":{},"source":["create mapping keyword-id"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["dictionary = corpora.Dictionary(texts)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Mapping keyword-id:\n","{'air': 15,\n"," 'aspir': 18,\n"," 'cake': 4,\n"," 'cool': 16,\n"," 'day': 0,\n"," 'eat': 1,\n"," 'holiday': 2,\n"," 'like': 5,\n"," 'movi': 14,\n"," 'museum': 17,\n"," 'race': 6,\n"," 'snail': 9,\n"," 'space': 11,\n"," 'star': 19,\n"," 'thanksgiv': 7,\n"," 'time': 12,\n"," 'travel': 13,\n"," 'trot': 8,\n"," 'turkey': 3,\n"," 'turtl': 10}\n"]}],"source":["print()\n","print(\"Mapping keyword-id:\")\n","pprint(dictionary.token2id)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["id2token = dict(dictionary.items())"]},{"cell_type":"markdown","metadata":{},"source":["create the vector for each doc"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["model_bow = [dictionary.doc2bow(text) for text in texts]"]},{"cell_type":"markdown","metadata":{},"source":["create the LDA model from bow vectors"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["lda = models.LdaModel(model_bow, num_topics=2, id2word=dictionary, random_state=30)\n","# random_state: forced to always obtain the same results in all the executions\n","lda_vectors = []\n","for v in model_bow:\n","    lda_vectors.append(lda[v])"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","LDA vectors for docs (in terms of topics):\n","[(0, 0.89354247), (1, 0.1064575)] eat turkey on turkey day holiday\n","[(0, 0.88823485), (1, 0.1117652)] i like to eat cake on holiday\n","[(0, 0.19518845), (1, 0.80481154)] turkey trot race on thanksgiving holiday\n","[(0, 0.1410767), (1, 0.8589233)] snail race the turtle\n","[(0, 0.1557929), (1, 0.84420705)] time travel space race\n","[(0, 0.20982431), (1, 0.7901757)] movie on thanksgiving\n","[(0, 0.12486146), (1, 0.8751385)] movie at air and space museum is cool movie\n","[(0, 0.15395802), (1, 0.846042)] aspiring movie star\n"]}],"source":["print()\n","print(\"LDA vectors for docs (in terms of topics):\")\n","i = 0\n","for v in lda_vectors:\n","    print(v, documents[i])\n","    i += 1"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Matrix similarities\n","MatrixSimilarity<8 docs, 2 features>\n"]}],"source":["matrix_lda = similarities.MatrixSimilarity(lda_vectors)\n","print()\n","print(\"Matrix similarities\")\n","print(matrix_lda)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def convert(match):\n","    return dictionary.id2token[int(match.group(0)[1:-1])]"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["LDA Topics:\n","(0, '0.099*\"holiday\" + 0.090*\"eat\" + 0.088*\"turkey\" + 0.070*\"movi\" + 0.056*\"race\" + 0.055*\"like\" + 0.053*\"cake\" + 0.052*\"space\" + 0.048*\"thanksgiv\" + 0.045*\"day\" + 0.043*\"air\" + 0.041*\"cool\" + 0.040*\"time\" + 0.037*\"museum\" + 0.037*\"travel\" + 0.032*\"star\" + 0.032*\"trot\" + 0.031*\"aspir\" + 0.025*\"turtl\" + 0.025*\"snail\"')\n","(1, '0.119*\"movi\" + 0.095*\"race\" + 0.068*\"turkey\" + 0.066*\"thanksgiv\" + 0.062*\"space\" + 0.058*\"holiday\" + 0.050*\"snail\" + 0.050*\"turtl\" + 0.045*\"aspir\" + 0.044*\"trot\" + 0.044*\"star\" + 0.040*\"travel\" + 0.039*\"museum\" + 0.037*\"time\" + 0.036*\"cool\" + 0.034*\"air\" + 0.033*\"day\" + 0.029*\"eat\" + 0.026*\"cake\" + 0.024*\"like\"')\n"]}],"source":["print(\"LDA Topics:\")\n","for t in lda.print_topics(num_words=30):\n","    print(re.sub('\"[0-9]+\"', convert, str(t)))"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["end_creation_model_t: datetime = datetime.datetime.now()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]}],"source":["print()"]},{"cell_type":"markdown","metadata":{},"source":["obtain LDA vector for the following doc<br>\n","doc = \"Human computer interaction\""]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["['tree', 'graph', 'human']"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["doc = \"trees graph human\"\n","doc_s = [porter.stem(word) for word in doc.lower().split() if word not in stoplist]\n","doc_s"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["vec_bow = dictionary.doc2bow(doc_s)\n","vec_lda = lda[vec_bow]"]},{"cell_type":"markdown","metadata":{},"source":["calculate similarities between doc and each doc of texts using lda vectors and cosine"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["sims = matrix_lda[vec_lda]"]},{"cell_type":"markdown","metadata":{},"source":["sort similarities in descending order"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["sims = sorted(enumerate(sims), key=lambda item: -item[1])"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Given the doc: trees graph human\n","whose LDA vector is: [(0, 0.5), (1, 0.5)]\n","\n","The Similarities between this doc and the documents of the corpus are:\n","0.8648992 movie on thanksgiving\n","0.85384667 turkey trot race on thanksgiving holiday\n","0.82369024 time travel space race\n","0.82227826 aspiring movie star\n","0.812363 snail race the turtle\n","0.7998936 movie at air and space museum is cool movie\n","0.7898527 i like to eat cake on holiday\n","0.7857948 eat turkey on turkey day holiday\n"]}],"source":["print()\n","print(\"Given the doc: \" + doc)\n","print(\"whose LDA vector is: \" + str(vec_lda))\n","print()\n","print(\"The Similarities between this doc and the documents of the corpus are:\")\n","for doc_position, doc_score in sims:\n","    print(doc_score, documents[doc_position])"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["end_t: datetime = datetime.datetime.now()"]},{"cell_type":"markdown","metadata":{},"source":["get execution time"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Execution time model: 0:00:27.097211 seconds\n","Execution time comparison: 0:00:10.055980 seconds\n"]}],"source":["elapsed_time_model_creation: datetime = end_creation_model_t - init_t\n","elapsed_time_comparison: datetime = end_t - end_creation_model_t\n","print()\n","print('Execution time model:', elapsed_time_model_creation, 'seconds')\n","print('Execution time comparison:', elapsed_time_comparison, 'seconds')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":2}
