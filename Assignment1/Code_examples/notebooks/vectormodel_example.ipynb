{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from gensim import corpora\n", "from pprint import pprint  # pretty-printer\n", "import re"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from nltk.corpus import stopwords"]}, {"cell_type": "markdown", "metadata": {}, "source": ["a corpus of 9 short documents"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["documents = [\n", "    \"Human machine survey computer interface interface eps time for lab abc computer applications user\",\n", "    \"A survey of user opinion of computer system user response time computer user interface interface\",\n", "    \"The EPS user users interfaces interface human interface computer human management system user\",\n", "    \"System and human interface interface engineering testing of EPS computer user\",\n", "    \"Relation of users perceived response time to error measurement trees\",\n", "    \"The generation of random binary unordered paths minors user user computer\",\n", "    \"The intersection graph of paths in trees paths trees\",\n", "    \"Graph minors IV Widths of trees and well quasi ordering graph paths\",\n", "    \"Graph minors A tree paths binary trees graphs\",\n", "]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["remove common words and tokenize"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stoplist = stopwords.words('english')\n", "texts = [ # we filter all the words considered as stopwords\n", "    [word for word in document.lower().split() if word not in stoplist]\n", "    for document in documents\n", "]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Tokens of each document:\")\n", "pprint(texts)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["create mapping keyword-id"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dictionary = corpora.Dictionary(texts)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print()\n", "print(\"Mapping keyword-id:\")\n", "pprint(dictionary.token2id)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["create a list of 9 vectors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_bow = [dictionary.doc2bow(text) for text in texts]  # for each document in the corpus, we create a vector"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["id2token = dict(dictionary.items())  # only to create a visualisation of the dictionary"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def convert(match):\n", "    return dictionary.id2token[int(match.group(0)[0:-1])]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print()\n", "print(\"Vectors for documents (the positions with zeros are not shown):\")\n", "for doc in model_bow:\n", "    print(re.sub(\"[0-9]+,\", convert, str(doc)))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}