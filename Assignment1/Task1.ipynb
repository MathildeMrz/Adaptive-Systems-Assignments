{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import re\n", "import csv\n", "import datetime"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from gensim import corpora\n", "from gensim import models\n", "from gensim import similarities\n", "from pprint import pprint  # pretty-printer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from nltk import PorterStemmer\n", "from nltk.corpus import stopwords"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["init_t: datetime = datetime.datetime.now()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "TASK 1 <br>\n", "Implement the following pseudocode to calculate the variable ratio_quality using the TFIDF vectors:<br>\n", "total_goods = 0<br>\n", "For every article (a) on topic \"Food and Drink\":<br>\n", "   Obtain the top-10 most similar articles (top-10) in Corpus to a<br>\n", "   Count how many articles in top-10 are related to topic \"Food and Drink\" (goods)<br>\n", "   total_goods = total_goods + goods<br>\n", "ratio_quality = total_goods/(num_articles_food_and_drink*10)<br>\n", "And measure the execution times separately for the following two subprocesses: <br>\n", "Creating the model (from the program begin to the call similarities.MatrixSimilarity(tfidf_vectors))<br>\n", "Implementation of the pseudocode above.<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["import our csv file and read it"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["csv_file_path = './news.csv'\n", "csv_full_text = \"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["with open(csv_file_path, newline='') as csvfile:\n", "    reader = csv.reader(csvfile)\n", "    for row in reader:\n", "        row_text = ' '.join(row)\n", "        csv_full_text += row_text + '\\n'\n", "# print the text \n", "print(csv_full_text)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["porter = PorterStemmer()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["remove common words and tokenize"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stoplist = stopwords.words('english')\n", "texts = [\n", "    [porter.stem(word) for word in csv_full_text.lower().split() if word not in stoplist]\n", "    for csv_full_text in csv_full_text\n", "]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["create mapping keyword-id"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dictionary = corpora.Dictionary(texts)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print()\n", "print(\"Mapping keyword-id:\")\n", "pprint(dictionary.token2id)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["id2token = dict(dictionary.items())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["create the vector for each doc"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_bow = [dictionary.doc2bow(text) for text in texts]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["create the LDA model from bow vectors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lda = models.LdaModel(model_bow, num_topics=2, id2word=dictionary, random_state=30)\n", "# random_state: forced to always obtain the same results in all the executions\n", "lda_vectors = []\n", "for v in model_bow:\n", "    lda_vectors.append(lda[v])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print()\n", "print(\"LDA vectors for docs (in terms of topics):\")\n", "i = 0\n", "for v in lda_vectors:\n", "    print(v, documents[i])\n", "    i += 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["matrix_lda = similarities.MatrixSimilarity(lda_vectors)\n", "print()\n", "print(\"Matrix similarities\")\n", "print(matrix_lda)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def convert(match):\n", "    return dictionary.id2token[int(match.group(0)[1:-1])]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"LDA Topics:\")\n", "for t in lda.print_topics(num_words=30):\n", "    print(re.sub('\"[0-9]+\"', convert, str(t)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["end_creation_model_t: datetime = datetime.datetime.now()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["obtain LDA vector for the following doc<br>\n", "doc = \"Human computer interaction\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["doc = \"trees graph human\"\n", "doc_s = [porter.stem(word) for word in doc.lower().split() if word not in stoplist]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vec_bow = dictionary.doc2bow(doc_s)\n", "vec_lda = lda[vec_bow]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["calculate similarities between doc and each doc of texts using lda vectors and cosine"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sims = matrix_lda[vec_lda]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["sort similarities in descending order"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sims = sorted(enumerate(sims), key=lambda item: -item[1])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print()\n", "print(\"Given the doc: \" + doc)\n", "print(\"whose LDA vector is: \" + str(vec_lda))\n", "print()\n", "print(\"The Similarities between this doc and the documents of the corpus are:\")\n", "for doc_position, doc_score in sims:\n", "    print(doc_score, documents[doc_position])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["end_t: datetime = datetime.datetime.now()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["get execution time"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["elapsed_time_model_creation: datetime = end_creation_model_t - init_t\n", "elapsed_time_comparison: datetime = end_t - end_creation_model_t\n", "print()\n", "print('Execution time model:', elapsed_time_model_creation, 'seconds')\n", "print('Execution time comparison:', elapsed_time_comparison, 'seconds')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}