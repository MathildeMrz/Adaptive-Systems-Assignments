{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import datetime\n","import csv\n","\n","from gensim import corpora\n","from gensim import models\n","from pprint import pprint  # pretty-printer\n","from gensim import similarities\n","\n","import re\n","\n","from nltk.corpus import stopwords\n","from nltk import PorterStemmer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["init_t: datetime = datetime.datetime.now()  # init the time for the execution time calculation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["news_file = \"news.csv\""]},{"cell_type":"markdown","metadata":{},"source":["CSV extraction #"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["all_news = []\n","descriptions = []\n","#food_drink_news = []"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open(news_file, 'r', newline='', encoding='utf-8') as csv_file:\n","    reader_csv = csv.reader(csv_file)\n","    for line in reader_csv:\n","        all_news.append(line)\n","        descriptions.append(line[3])\n","\n","        #if \")Food & Drink\" in line[2]:\n","            #food_drink_news.append(line)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# delete the first row 'description' name\n","descriptions.pop(0)\n","descriptions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["porter = PorterStemmer()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# remove common words and tokenize\n","stoplist = stopwords.words('english')\n","texts = [\n","    [porter.stem(word) for word in document.lower().split() if word not in stoplist]\n","    for document in descriptions\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Tokens of each document:\")\n","texts"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create mapping keyword-id\n","dictionary = corpora.Dictionary(texts)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print()\n","print(\"Mapping keyword-id:\")\n","pprint(dictionary.token2id)"]},{"cell_type":"markdown","metadata":{},"source":["create the vector for each doc"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_bow = [dictionary.doc2bow(text) for text in texts]"]},{"cell_type":"markdown","metadata":{},"source":["create tfidf model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tfidf = models.TfidfModel(model_bow)\n","tfidf_vectors = tfidf[model_bow]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["id2token = dict(dictionary.items())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def convert(match):\n","    return dictionary.id2token[int(match.group(0)[0:-1])]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print()\n","print(\"Vectors for documents (the positions with zeros are not shown):\")\n","for doc in tfidf_vectors:\n","    print(re.sub(\"[0-9]+,\", convert, str(doc)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["matrix_tfidf = similarities.MatrixSimilarity(tfidf_vectors)  # this matrix will be necessary to calculate similarity between documents"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["end_creation_model_t: datetime = datetime.datetime.now()  # just after the calculation of the matrix similarity -> time function"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print()\n","print(\"Matrix similarities\")\n","print(matrix_tfidf)"]},{"cell_type":"markdown","metadata":{},"source":["obtain tfidf vector for the following doc"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["doc = \"trees graph human\"\n","doc_s = [porter.stem(word) for word in doc.lower().split() if word not in stoplist]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vec_bow = dictionary.doc2bow(doc_s)\n","vec_tfidf = tfidf[vec_bow]"]},{"cell_type":"markdown","metadata":{},"source":["calculate similarities between doc and each doc of texts using tfidf vectors and cosine"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sims = matrix_tfidf[vec_tfidf]  # sims is a list a similarities"]},{"cell_type":"markdown","metadata":{},"source":["sort similarities in descending order"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sims = sorted(enumerate(sims), key=lambda item: -item[1])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print()\n","print(\"Given the doc: \" + doc)\n","print(\"whose tfidf vector is: \" + str(vec_tfidf))\n","print()\n","print(\"The Similarities between this doc and the documents of the corpus are:\")\n","for doc_position, doc_score in sims:\n","    print(doc_score, descriptions[doc_position])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["end_t: datetime = datetime.datetime.now()  # to mark the end of the program"]},{"cell_type":"markdown","metadata":{},"source":["get execution time"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["elapsed_time_model_creation: datetime = end_creation_model_t - init_t\n","elapsed_time_comparison: datetime = end_t - end_creation_model_t\n","print()\n","print('Execution time model:', elapsed_time_model_creation, 'seconds')\n","print('Execution time comparison:', elapsed_time_comparison, 'seconds')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":2}
